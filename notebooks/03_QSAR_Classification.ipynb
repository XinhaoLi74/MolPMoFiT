{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSAR/QSPR Models Fine-Tuning 1: Classification \n",
    "\n",
    "This notebook is an example of a classification task on BBBP dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import RDLogger \n",
    "RDLogger.DisableLog('rdApp.*') # switch off RDKit warning messages\n",
    "\n",
    "import pickle\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from utils import *\n",
    "\n",
    "torch.cuda.set_device(1) #change to 0 if you only has one GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../results')\n",
    "name = 'BBBP'\n",
    "path = data_path/name\n",
    "path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (2039, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>p_np</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Cl].CC(C)NCC(O)COc1cccc2ccccc12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             smiles  p_np\n",
       "0  [Cl].CC(C)NCC(O)COc1cccc2ccccc12     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbbp_data = pd.read_csv('../data/QSAR/bbbp.csv')\n",
    "print('Dataset:', bbbp_data.shape)\n",
    "bbbp_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We benchmarked our MolPMoFiT method to other published models from [Yang et al](https://pubs.acs.org/doi/abs/10.1021/acs.jcim.9b00237) on\n",
    "three well-studied datasets: **lipophilicity**, **HIV** and **BBBP**. All the models were evaluated on the\n",
    "same ten 80:10:10 [splits](https://github.com/swansonk14/chemprop/blob/master/splits.tar.gz) from Yang et al to ensure a fair and reproducible benchmark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: 1631\n",
      "Valid Set: 204\n",
      "Test Set: 204\n"
     ]
    }
   ],
   "source": [
    "# Change the split type and id to nagivate different splits.\n",
    "dataset = 'bbbp'\n",
    "split_type = 'random'\n",
    "split_id = 11\n",
    "\n",
    "split_file = f'{dataset}/{split_type}/split_indices{split_id}.pckl'\n",
    "\n",
    "with open(f'../data/QSAR/splits/{split_file}', 'rb') as f:\n",
    "    split = pickle.load(f)\n",
    "    \n",
    "print('Train Set:', len(split[0]))\n",
    "print('Valid Set:', len(split[1]))\n",
    "print('Test Set:', len(split[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sample: 1259 151 150\n"
     ]
    }
   ],
   "source": [
    "train = bbbp_data.iloc[split[0]]\n",
    "valid = bbbp_data.iloc[split[1]]\n",
    "test = bbbp_data.iloc[split[2]]\n",
    "print('Positive Sample:',np.sum(train.p_np == 1), np.sum(valid.p_np == 1), np.sum(test.p_np == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbbp_smiles_augmentation(df, N_rounds):\n",
    "    dist_aug = {col_name: [] for col_name in df}\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        if df.iloc[i].p_np == 1:\n",
    "            for j in range(N_rounds[0]):\n",
    "                dist_aug['smiles'].append(randomize_smiles(df.iloc[i].smiles))\n",
    "                dist_aug['p_np'].append(df.iloc[i]['p_np'])\n",
    "\n",
    "        if df.iloc[i].p_np == 0:\n",
    "            for j in range(N_rounds[1]):\n",
    "                dist_aug['smiles'].append(randomize_smiles(df.iloc[i].smiles))\n",
    "                dist_aug['p_np'].append(df.iloc[i]['p_np'])\n",
    "        \n",
    "    df_aug = pd.DataFrame.from_dict(dist_aug)\n",
    "    df_aug = df_aug.append(df, ignore_index=True)\n",
    "    return df_aug.drop_duplicates('smiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the dataset is not balanced. For training data, we generated 10 and 30 randomized SMILES for molecules belong to the positive and negative classes, respectively. The numbers can be changed based on different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_aug Samples: 23873\n",
      "Positive:Negative 1.1944112510341025\n",
      "Valid_aug Samples: 1195\n",
      "Positive:Negative 2.805732484076433\n"
     ]
    }
   ],
   "source": [
    "train_aug = bbbp_smiles_augmentation(train, [10,30])\n",
    "valid_aug = bbbp_smiles_augmentation(valid, [5,5])\n",
    "\n",
    "print('Train_aug Samples:', train_aug.shape[0])\n",
    "print('Positive:Negative',np.sum(train_aug.p_np == 1)/ np.sum(train_aug.p_np == 0))\n",
    "\n",
    "print('Valid_aug Samples:', valid_aug.shape[0])\n",
    "print('Positive:Negative',np.sum(valid_aug.p_np == 1)/ np.sum(valid_aug.p_np == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adpot the Encoder of MSPM According to the Target Dataset.\n",
    "\n",
    "In order to fine-tuning the pre-trained MSPM on the QSAR datasets of interest, we need to prepare the data:\n",
    "\n",
    "- Tokenize the SMILES of the QSAR dataset.\n",
    "- Align the token IDs of the QSAR dataset to the token IDs pre-trained MSPM. \n",
    "\n",
    "Often, the vocab size of the QSAR dataset is different from that of the pre-trained strcuture prediction model, which means the QSAR model will have a different input size from that of pre-trained model. Here, we need to change the input size of the pre-trained model to the vocab size of the QSAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "tok = Tokenizer(partial(MolTokenizer, special_tokens = special_tokens), n_cpus=6, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 48\n"
     ]
    }
   ],
   "source": [
    "qsar_vocab = TextLMDataBunch.from_df(path, train_aug, valid_aug, bs=bs, tokenizer=tok, \n",
    "                              chunksize=50000, text_cols=0,label_cols=1, max_vocab=60000, include_bos=False)\n",
    "\n",
    "print(f'Vocab Size: {len(qsar_vocab.vocab.itos)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = Path('../results/MSPM/models')\n",
    "\n",
    "pretrained_fnames = ['MSPM_wt', 'MSPM_vocab']\n",
    "fnames = [pretrained_model_path/f'{fn}.{ext}' for fn,ext in zip(pretrained_fnames, ['pth', 'pkl'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_learner = language_model_learner(qsar_vocab, AWD_LSTM, drop_mult=1.0)\n",
    "lm_learner = lm_learner.load_pretrained(*fnames)\n",
    "lm_learner.freeze()\n",
    "lm_learner.save_encoder(f'lm_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databunch for QSAR Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to change the `text_cols` and `label_col` based on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas = TextClasDataBunch.from_df(path, train_aug, valid_aug, bs=bs, tokenizer=tok, \n",
    "                                          chunksize=50000, text_cols='smiles',label_cols='p_np', \n",
    "                                          vocab=qsar_vocab.vocab, max_vocab=60000, include_bos=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_learner = text_classifier_learner(data_clas, AWD_LSTM, pretrained=False, drop_mult=0.2, callback_fns=AUROC)\n",
    "cls_learner.load_encoder(f'lm_encoder')\n",
    "cls_learner.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.407379</td>\n",
       "      <td>0.460653</td>\n",
       "      <td>0.797490</td>\n",
       "      <td>0.884794</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.318413</td>\n",
       "      <td>0.455647</td>\n",
       "      <td>0.834310</td>\n",
       "      <td>0.882303</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.270218</td>\n",
       "      <td>0.396474</td>\n",
       "      <td>0.854393</td>\n",
       "      <td>0.913720</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204793</td>\n",
       "      <td>0.370928</td>\n",
       "      <td>0.876987</td>\n",
       "      <td>0.917120</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_learner.fit_one_cycle(4, 3e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.209718</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.871130</td>\n",
       "      <td>0.912704</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.164111</td>\n",
       "      <td>0.451916</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.915477</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.100156</td>\n",
       "      <td>0.424936</td>\n",
       "      <td>0.890377</td>\n",
       "      <td>0.926186</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.077003</td>\n",
       "      <td>0.429915</td>\n",
       "      <td>0.888703</td>\n",
       "      <td>0.922358</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_learner.freeze_to(-2)\n",
    "cls_learner.fit_one_cycle(4, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.081082</td>\n",
       "      <td>0.440379</td>\n",
       "      <td>0.889540</td>\n",
       "      <td>0.922670</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.070148</td>\n",
       "      <td>0.460488</td>\n",
       "      <td>0.888703</td>\n",
       "      <td>0.917572</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.095224</td>\n",
       "      <td>0.472792</td>\n",
       "      <td>0.887866</td>\n",
       "      <td>0.923655</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.081094</td>\n",
       "      <td>0.458418</td>\n",
       "      <td>0.888703</td>\n",
       "      <td>0.925186</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_learner.freeze_to(-3)\n",
    "cls_learner.fit_one_cycle(4, slice(5e-4/(2.6**4),5e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.093497</td>\n",
       "      <td>0.467894</td>\n",
       "      <td>0.888703</td>\n",
       "      <td>0.920641</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.094730</td>\n",
       "      <td>0.486960</td>\n",
       "      <td>0.887866</td>\n",
       "      <td>0.919988</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.094285</td>\n",
       "      <td>0.450275</td>\n",
       "      <td>0.892887</td>\n",
       "      <td>0.922824</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.068093</td>\n",
       "      <td>0.469609</td>\n",
       "      <td>0.883682</td>\n",
       "      <td>0.921969</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.063156</td>\n",
       "      <td>0.459041</td>\n",
       "      <td>0.887866</td>\n",
       "      <td>0.923721</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.057931</td>\n",
       "      <td>0.449040</td>\n",
       "      <td>0.886192</td>\n",
       "      <td>0.925472</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls_learner.unfreeze()\n",
    "cls_learner.fit_one_cycle(6, slice(5e-5/(2.6**4),5e-5), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_learner.save(f'{split_type}_{split_id}_clas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Test only on Canoicial SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_clas = TextClasDataBunch.from_df(path, train, test, bs=bs, tokenizer=tok, \n",
    "                              chunksize=50000, text_cols='smiles',label_cols='p_np', vocab=qsar_vocab.vocab, max_vocab=60000,\n",
    "                                              include_bos=False)\n",
    "\n",
    "learner = text_classifier_learner(test_data_clas, AWD_LSTM, pretrained=False, drop_mult=0.2)\n",
    "learner.load(f'{split_type}_{split_id}_clas', purge=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 204 molecues\n",
      "Accuracy: 0.922\n",
      "False Positives: 0.049\n",
      "False Negatives: 0.029\n",
      "Recall: 0.960\n",
      "Precision: 0.935\n",
      "Sensitivity: 0.960\n",
      "Specificity: 0.815\n",
      "MCC: 0.795\n",
      "ROCAUC: 0.943\n"
     ]
    }
   ],
   "source": [
    "test_get_scores(learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Test on averaging prediction of canoicial and randomized SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_smiles_augmentation(df):\n",
    "    dist_aug = {col_name: [] for col_name in df}\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        dist_aug['smiles'].append(randomize_smiles(df.iloc[i]['smiles']))\n",
    "        dist_aug['p_np'].append(df.iloc[i]['p_np'])\n",
    "                     \n",
    "    return pd.DataFrame.from_dict(dist_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = torch.tensor(test['p_np'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "# Randomized SMILES Predictions\n",
    "for i in range(4):\n",
    "    np.random.seed(12*i)    \n",
    "    test_aug = test_smiles_augmentation(test)\n",
    "    \n",
    "    # model\n",
    "    test_data_clas = TextClasDataBunch.from_df(path, train, test_aug, bs=bs, tokenizer=tok, \n",
    "                              chunksize=50000, text_cols='smiles',label_cols='p_np', vocab=qsar_vocab.vocab, max_vocab=60000,\n",
    "                                              include_bos=False)\n",
    "    learner = text_classifier_learner(test_data_clas, AWD_LSTM, pretrained=False, drop_mult=0.2)\n",
    "    learner.load(f'{split_type}_{split_id}_clas', purge=False);\n",
    "    \n",
    "    \n",
    "    #get predictions\n",
    "    pred,lbl = learner.get_preds(ordered=True)\n",
    "    \n",
    "    preds.append(pred)\n",
    "\n",
    "# Canonical SMILES Predictions\n",
    "\n",
    "test_data_clas = TextClasDataBunch.from_df(path, train, test, bs=bs, tokenizer=tok, \n",
    "                              chunksize=50000, text_cols='smiles',label_cols='p_np', vocab=qsar_vocab.vocab, max_vocab=60000,\n",
    "                                              include_bos=False)\n",
    "\n",
    "learner = text_classifier_learner(test_data_clas, AWD_LSTM, pretrained=False, drop_mult=0.2)\n",
    "learner.load(f'{split_type}_{split_id}_clas', purge=False);\n",
    "\n",
    "\n",
    "pred,lbl = learner.get_preds(ordered=True)\n",
    "\n",
    "\n",
    "preds.append(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Averaging Predictions of Canoicial and Randomized SMILES: 0.943\n"
     ]
    }
   ],
   "source": [
    "avg_preds = sum(preds)/len(preds)\n",
    "print(f'Performance of Averaging Predictions of Canoicial and Randomized SMILES: {roc_auc_score(lbl, avg_preds[:,1]):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
